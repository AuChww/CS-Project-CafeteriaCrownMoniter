# à¸„à¸±à¸”à¹€à¸­à¸²à¸¡à¸²à¹à¸„à¹ˆ 5 à¸§à¸´à¹à¸£à¸
import torch
import cv2
import numpy as np
import os
from ultralytics import YOLO

# import os
# os.environ['QT_QPA_PLATFORM'] = 'xcb'
# os.environ['QT_QPA_PLATFORM_PLUGIN_PATH'] = '/usr/lib/x86_64-linux-gnu/qt5/plugins/platforms'

model = YOLO('yoloModel/yolov8s.pt')  

face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')

def get_zone_human_count(video_id):

    video_path = os.path.join(os.path.dirname(__file__), f"../public/video/zone/{video_id}.mp4")
        # à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸šà¸§à¹ˆà¸²à¹„à¸Ÿà¸¥à¹Œà¸¡à¸µà¸­à¸¢à¸¹à¹ˆà¸ˆà¸£à¸´à¸‡à¸«à¸£à¸·à¸­à¹„à¸¡à¹ˆ
    if not os.path.exists(video_path):
        print(f"Video file for zone {video_id} not found.")
        return 0  
    
    cap = cv2.VideoCapture(video_path)
    
    roi_zones = {
        1: {"top_left": (50, 50), "bottom_right": (1500, 1500)},
        2: {"top_left": (50, 50), "bottom_right": (1500, 1500)},
        3: {"top_left": (100, 100), "bottom_right": (1400, 1400)}
    }

    # à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸šà¸§à¹ˆà¸²à¸¡à¸µà¸à¸²à¸£à¸à¸³à¸«à¸™à¸”à¹‚à¸‹à¸™à¸™à¸µà¹‰à¸«à¸£à¸·à¸­à¹„à¸¡à¹ˆ
    if id in roi_zones:
        roi_top_left = roi_zones[id]["top_left"]
        roi_bottom_right = roi_zones[id]["bottom_right"]
    else:
        roi_top_left = (50,50)
        roi_bottom_right = (1500, 1500)  

    # à¸•à¸±à¸§à¹à¸›à¸£à¹€à¸à¹‡à¸šà¸ˆà¸³à¸™à¸§à¸™à¸„à¸™à¹ƒà¸™à¹à¸•à¹ˆà¸¥à¸°à¹€à¸Ÿà¸£à¸¡
    all_human_counts = []
    frame_number = 0

    # à¸«à¸²à¸„à¸§à¸²à¸¡à¸¢à¸²à¸§à¸‚à¸­à¸‡à¸§à¸´à¸”à¸µà¹‚à¸­ (à¹ƒà¸™à¸«à¸™à¹ˆà¸§à¸¢à¹€à¸Ÿà¸£à¸¡)
    fps = cap.get(cv2.CAP_PROP_FPS)  # Frames per second
    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))

    # à¸„à¸³à¸™à¸§à¸“à¸ˆà¸³à¸™à¸§à¸™à¹€à¸Ÿà¸£à¸¡à¸—à¸µà¹ˆà¸•à¹‰à¸­à¸‡à¸à¸²à¸£à¹ƒà¸«à¹‰à¹„à¸”à¹‰ 5 à¸§à¸´à¸™à¸²à¸—à¸µ
    frames_to_process = int(fps * 1)  # 1 à¸§à¸´à¸™à¸²à¸—à¸µà¹à¸£à¸

    while True:
        ret, frame = cap.read()
        if not ret or frame_number >= frames_to_process:
            break  # à¸­à¸­à¸à¸ˆà¸²à¸ loop à¸–à¹‰à¸²à¸«à¸¡à¸”à¸§à¸´à¸”à¸µà¹‚à¸­à¸«à¸£à¸·à¸­à¸›à¸£à¸°à¸¡à¸§à¸¥à¸œà¸¥à¸„à¸£à¸š 5 à¸§à¸´à¸™à¸²à¸—à¸µ

        frame_number += 1

        # à¸‚à¹‰à¸²à¸¡à¸—à¸¸à¸ à¹† 10 à¹€à¸Ÿà¸£à¸¡
        if frame_number % 10 != 0:
            continue

        results = model(frame)
        detections = results[0].boxes.xyxy.cpu().numpy()  # à¸”à¸¶à¸‡à¸‚à¹‰à¸­à¸¡à¸¹à¸¥ bounding boxes
        classes = results[0].boxes.cls.cpu().numpy()     # à¸”à¸¶à¸‡à¸‚à¹‰à¸­à¸¡à¸¹à¸¥ class
        
        human_count = 0

        for i, box in enumerate(detections):
            left, top, right, bottom = map(int, box[:4])
            cls = int(classes[i])

            # à¸•à¸£à¸§à¸ˆà¸ˆà¸±à¸šà¹€à¸‰à¸žà¸²à¸°à¸„à¸™ à¹à¸¥à¸°à¸­à¸¢à¸¹à¹ˆà¹ƒà¸™ ROI
            if cls == 0 and (left > roi_top_left[0] and right < roi_bottom_right[0] and
                             top > roi_top_left[1] and bottom < roi_bottom_right[1]):  
                human_count += 1

        all_human_counts.append(human_count)

       
        if frame_number % 30 == 0:
            print(f"Frame {frame_number}: zone {video_id} : Human Count = {human_count}")
            
        # cv2.imshow('YOLOv8 Human Detection', frame)

    cap.release()
    cv2.destroyAllWindows()

    # à¸„à¸·à¸™à¸„à¹ˆà¸²à¸•à¸±à¸§à¸ªà¸¸à¸”à¸—à¹‰à¸²à¸¢à¸‚à¸­à¸‡ all_human_counts
    return all_human_counts[-1] if all_human_counts else 0


# def get_zone_human_count(video_id):
#     video_path = os.path.join(os.path.dirname(__file__), f"../public/video/zone/{video_id}.mp4")

#     # à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸šà¸§à¹ˆà¸²à¹„à¸Ÿà¸¥à¹Œà¸¡à¸µà¸­à¸¢à¸¹à¹ˆà¸ˆà¸£à¸´à¸‡à¸«à¸£à¸·à¸­à¹„à¸¡à¹ˆ
#     if not os.path.exists(video_path):
#         print(f"Video file for zone {video_id} not found.")
#         return 0  
    
#     cap = cv2.VideoCapture(video_path)
    
#     roi_zones = {
#         1: {"top_left": (50, 50), "bottom_right": (1500, 1500)},
#         2: {"top_left": (50, 50), "bottom_right": (1500, 1500)},
#         3: {"top_left": (100, 100), "bottom_right": (1400, 1400)}
#     }

#     # à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸šà¸§à¹ˆà¸²à¹‚à¸‹à¸™à¸—à¸µà¹ˆà¸à¸³à¸«à¸™à¸”à¸¡à¸µà¸­à¸¢à¸¹à¹ˆà¸«à¸£à¸·à¸­à¹„à¸¡à¹ˆ
#     if video_id in roi_zones:
#         roi_top_left = roi_zones[video_id]["top_left"]
#         roi_bottom_right = roi_zones[video_id]["bottom_right"]
#     else:
#         roi_top_left = (50, 50)
#         roi_bottom_right = (1500, 1500)  

#     all_human_counts = []
#     frame_number = 0

#     while True:
#         ret, frame = cap.read()
#         if not ret:  
#             break  # à¸­à¸­à¸à¸ˆà¸²à¸ loop à¸–à¹‰à¸²à¸«à¸¡à¸”à¸§à¸´à¸”à¸µà¹‚à¸­

#         frame_number += 1

#         results = model(frame)
#         detections = results[0].boxes.xyxy.cpu().numpy()  # à¸”à¸¶à¸‡à¸‚à¹‰à¸­à¸¡à¸¹à¸¥ bounding boxes
#         classes = results[0].boxes.cls.cpu().numpy()     # à¸”à¸¶à¸‡à¸‚à¹‰à¸­à¸¡à¸¹à¸¥ class
        
#         human_count = 0

#         for i, box in enumerate(detections):
#             left, top, right, bottom = map(int, box[:4])
#             cls = int(classes[i])

#             # à¸•à¸£à¸§à¸ˆà¸ˆà¸±à¸šà¹€à¸‰à¸žà¸²à¸°à¸„à¸™ à¹à¸¥à¸°à¸­à¸¢à¸¹à¹ˆà¹ƒà¸™ ROI
#             if cls == 0 and (left > roi_top_left[0] and right < roi_bottom_right[0] and
#                              top > roi_top_left[1] and bottom < roi_bottom_right[1]):  
#                 human_count += 1

#                 # ðŸ”¥ à¸§à¸²à¸”à¸à¸£à¸­à¸šà¸£à¸­à¸šà¸•à¸±à¸§à¸„à¸™
#                 cv2.rectangle(frame, (left, top), (right, bottom), (0, 0, 255), 2)  # à¸ªà¸µà¹à¸”à¸‡
#                 cv2.putText(frame, f"ID {i+1}", (left, top - 10), 
#                             cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)  # à¹à¸ªà¸”à¸‡à¹€à¸¥à¸‚ ID

#         all_human_counts.append(human_count)

#         # à¸§à¸²à¸”à¸à¸£à¸­à¸š ROI
#         cv2.rectangle(frame, roi_top_left, roi_bottom_right, (0, 255, 0), 2)  # à¸ªà¸µà¹€à¸‚à¸µà¸¢à¸§
#         cv2.putText(frame, f"Zone {video_id}: {human_count}", (roi_top_left[0], roi_top_left[1] - 10), 
#                     cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)

#         # à¹à¸ªà¸”à¸‡à¸«à¸™à¹‰à¸²à¸•à¹ˆà¸²à¸‡à¸§à¸´à¸”à¸µà¹‚à¸­
#         # cv2.imshow('YOLOv8 Human Detection', frame)

#         # à¸«à¸¢à¸¸à¸”à¸§à¸´à¸”à¸µà¹‚à¸­à¹€à¸¡à¸·à¹ˆà¸­à¸à¸” 'q'
#         if cv2.waitKey(1) & 0xFF == ord('q'):
#             break

#     cap.release()
#     cv2.destroyAllWindows()

#     # à¸„à¸·à¸™à¸„à¹ˆà¸²à¸•à¸±à¸§à¸ªà¸¸à¸”à¸—à¹‰à¸²à¸¢à¸‚à¸­à¸‡ all_human_counts
#     return all_human_counts[-1] if all_human_counts else 0


# get_zone_human_count(9)


def get_restaurant_human_count(restaurant_id_first,restaurant_id_second):
    video_path = os.path.join(os.path.dirname(__file__), f"../public/video/restaurant/{restaurant_id_first,restaurant_id_second}.mp4")
    
    if not os.path.exists(video_path):
        print(f"Video file {restaurant_id_first,restaurant_id_second} not found.")
        return 0  
    
    cap = cv2.VideoCapture(video_path)

    # à¸à¸³à¸«à¸™à¸” ROI (Region of Interest)
    roi_areas = {
        str(restaurant_id_first): [(0, 0), (425, 475)],  
        str(restaurant_id_second): [(425, 0), (850, 475)],
    }


    frame_number = 0
    human_counts = {zone: [] for zone in roi_areas}
    
    # à¸«à¸²à¸„à¸§à¸²à¸¡à¸¢à¸²à¸§à¸‚à¸­à¸‡à¸§à¸´à¸”à¸µà¹‚à¸­ (à¹ƒà¸™à¸«à¸™à¹ˆà¸§à¸¢à¹€à¸Ÿà¸£à¸¡)
    fps = cap.get(cv2.CAP_PROP_FPS)  # Frames per second
    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))

    frames_to_process = int(fps * 1)  # 1 à¸§à¸´à¸™à¸²à¸—à¸µà¹à¸£à¸

    while True:
        ret, frame = cap.read()
        if not ret or frame_number >= frames_to_process:
            break  # à¸­à¸­à¸à¸ˆà¸²à¸ loop à¸–à¹‰à¸²à¸«à¸¡à¸”à¸§à¸´à¸”à¸µà¹‚à¸­à¸«à¸£à¸·à¸­à¸›à¸£à¸°à¸¡à¸§à¸¥à¸œà¸¥à¸„à¸£à¸š 5 à¸§à¸´à¸™à¸²à¸—à¸µ

        frame_number += 1

        # à¸‚à¹‰à¸²à¸¡à¸à¸²à¸£à¸•à¸£à¸§à¸ˆà¸ˆà¸±à¸šà¸šà¸²à¸‡à¹€à¸Ÿà¸£à¸¡ à¹€à¸žà¸·à¹ˆà¸­à¸¥à¸”à¸ à¸²à¸£à¸° (à¹€à¸Šà¹ˆà¸™ à¸›à¸£à¸°à¸¡à¸§à¸¥à¸œà¸¥à¸—à¸¸à¸ 5 à¹€à¸Ÿà¸£à¸¡)
        if frame_number % 10 != 0:
            continue

        results = model(frame)
        detections = results[0].boxes.xyxy.cpu().numpy()
        classes = results[0].boxes.cls.cpu().numpy()

        current_counts = {zone: 0 for zone in roi_areas}

        for i, box in enumerate(detections):
            left, top, right, bottom = map(int, box[:4])
            cls = int(classes[i])

            if cls == 0:
                for zone, (roi_top_left, roi_bottom_right) in roi_areas.items():
                    if (left > roi_top_left[0] and right < roi_bottom_right[0] and
                        top > roi_top_left[1] and bottom < roi_bottom_right[1]):

                        current_counts[zone] += 1  # Update human count for the zone

                        # ðŸ”¥ à¸§à¸²à¸”à¸à¸£à¸­à¸šà¸£à¸­à¸šà¸•à¸±à¸§à¸„à¸™
                        cv2.rectangle(frame, (left, top), (right, bottom), (0, 0, 255), 2)

        # à¸šà¸±à¸™à¸—à¸¶à¸à¸ˆà¸³à¸™à¸§à¸™à¸„à¸™à¹ƒà¸™à¹à¸•à¹ˆà¸¥à¸° ROI
        for zone in roi_areas:
            human_counts[zone].append(current_counts[zone])

        # à¹à¸ªà¸”à¸‡à¸œà¸¥à¹à¸„à¹ˆà¸—à¸¸à¸à¹† 10 à¹€à¸Ÿà¸£à¸¡
        if frame_number % 60 == 0:
            for zone, (roi_top_left, roi_bottom_right) in roi_areas.items():
                cv2.rectangle(frame, roi_top_left, roi_bottom_right, (0, 0, 255), 2)
                cv2.putText(frame, f"{zone}: {current_counts[zone]}", (roi_top_left[0], roi_top_left[1] - 10),
                cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)

        if cv2.waitKey(1) & 0xFF == ord('q'):
            break

    cap.release()
    
    for zone in roi_areas:
        print(f"{zone}: {human_counts[zone][-1] if human_counts[zone] else 0}")

    print(f"success human count")

    return [ (zone, human_counts[zone][-1] if human_counts[zone] else 0) for zone in roi_areas ]
